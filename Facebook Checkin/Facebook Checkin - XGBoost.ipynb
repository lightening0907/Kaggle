{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113e14490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests, zipfile, StringIO\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import log_loss\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "import seaborn as sns\n",
    "# Plotting Options\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import cross_validation, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "from IPython.core.debugger import Tracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_csv_zip(filename):\n",
    "    z = zipfile.ZipFile(filename+'.zip')\n",
    "    df = pd.read_csv(z.open(filename),index_col=False)\n",
    "    return df\n",
    "train = read_csv_zip(\"train.csv\")\n",
    "test = read_csv_zip(\"test.csv\")\n",
    "train_sample = train.sample(frac=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_datetime(df):\n",
    "    df[\"time_dt\"] = pd.to_datetime(df[\"time\"]*60,unit='s')\n",
    "    df[\"year\"] = df[\"time_dt\"].apply( lambda x : x.year)\n",
    "    df[\"month\"] = df[\"time_dt\"].apply( lambda x : x.month)\n",
    "    df[\"day_of_week\"] = df[\"time_dt\"].apply( lambda x: x.weekday())\n",
    "    df[\"hour\"] = df[\"time_dt\"].apply( lambda x: x.hour)\n",
    "    df[\"day_of_year\"] = df[\"time_dt\"].apply( lambda x: x.dayofyear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sample= train.sample(frac=0.1) #switch to full training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sample = test.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = test_sample\n",
    "msk = np.random.rand(len(train_sample)) < 0.8\n",
    "train_data = train_sample[msk]\n",
    "val_data = train_sample[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unique_place_bins(df,bin_size):\n",
    "    df[\"x_bin\"] = df[\"x\"]*bin_size//df[\"x\"].max()\n",
    "    df[\"y_bin\"] = df[\"y\"]*bin_size//df[\"y\"].max()\n",
    "    dfbin = df.groupby([\"x_bin\",\"y_bin\"],as_index=False).agg({\"place_id\": lambda x: x.nunique()})\n",
    "    return dfbin\n",
    "    #dfreset = dfbin.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tot_checkin_bins(df):\n",
    "    dfbin = df.groupby([\"x_bin\",\"y_bin\"],as_index=False).size().reset_index()\n",
    "    return dfbin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "number_places = unique_place_bins(train_data,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_bin</th>\n",
       "      <th>y_bin</th>\n",
       "      <th>place_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x_bin  y_bin  place_id\n",
       "0      0      0        32\n",
       "1      0      1        39\n",
       "2      0      2        43\n",
       "3      0      3        45\n",
       "4      0      4        34"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_places.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_heatmaps(number_places,i):\n",
    "    number_places_pivot = number_places.pivot(\"x_bin\",\"y_bin\")\n",
    "    X=number_places_pivot.columns.levels[1].values\n",
    "    Y=number_places_pivot.index.values\n",
    "    Z=number_places_pivot.values\n",
    "    Xi,Yi = np.meshgrid(X, Y)\n",
    "    plt.figure(i,figsize=(8,6))\n",
    "    plt.contourf(Yi, Xi, Z, alpha=0.7, cmap=plt.cm.jet);\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"Y\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_datetime(train_data)\n",
    "get_datetime(test_data)\n",
    "get_datetime(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "      <th>place_id</th>\n",
       "      <th>x_bin</th>\n",
       "      <th>y_bin</th>\n",
       "      <th>time_dt</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1320825</th>\n",
       "      <td>1320825</td>\n",
       "      <td>4.5485</td>\n",
       "      <td>4.5476</td>\n",
       "      <td>419</td>\n",
       "      <td>182344</td>\n",
       "      <td>6383875308</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>1970-05-07 15:04:00</td>\n",
       "      <td>1970</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27814796</th>\n",
       "      <td>27814796</td>\n",
       "      <td>1.7018</td>\n",
       "      <td>3.5148</td>\n",
       "      <td>5</td>\n",
       "      <td>297348</td>\n",
       "      <td>1152196899</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>1970-07-26 11:48:00</td>\n",
       "      <td>1970</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28644887</th>\n",
       "      <td>28644887</td>\n",
       "      <td>5.3055</td>\n",
       "      <td>1.2691</td>\n",
       "      <td>56</td>\n",
       "      <td>691349</td>\n",
       "      <td>8187823707</td>\n",
       "      <td>53</td>\n",
       "      <td>12</td>\n",
       "      <td>1971-04-26 02:29:00</td>\n",
       "      <td>1971</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28755646</th>\n",
       "      <td>28755646</td>\n",
       "      <td>8.3078</td>\n",
       "      <td>5.2137</td>\n",
       "      <td>16</td>\n",
       "      <td>583604</td>\n",
       "      <td>4819761395</td>\n",
       "      <td>83</td>\n",
       "      <td>52</td>\n",
       "      <td>1971-02-10 06:44:00</td>\n",
       "      <td>1971</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5208006</th>\n",
       "      <td>5208006</td>\n",
       "      <td>3.9429</td>\n",
       "      <td>2.5444</td>\n",
       "      <td>47</td>\n",
       "      <td>712698</td>\n",
       "      <td>2438895977</td>\n",
       "      <td>39</td>\n",
       "      <td>25</td>\n",
       "      <td>1971-05-10 22:18:00</td>\n",
       "      <td>1971</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_id       x       y  accuracy    time    place_id  x_bin  \\\n",
       "1320825    1320825  4.5485  4.5476       419  182344  6383875308     45   \n",
       "27814796  27814796  1.7018  3.5148         5  297348  1152196899     17   \n",
       "28644887  28644887  5.3055  1.2691        56  691349  8187823707     53   \n",
       "28755646  28755646  8.3078  5.2137        16  583604  4819761395     83   \n",
       "5208006    5208006  3.9429  2.5444        47  712698  2438895977     39   \n",
       "\n",
       "          y_bin             time_dt  year  month  day_of_week  hour  \\\n",
       "1320825      45 1970-05-07 15:04:00  1970      5            3    15   \n",
       "27814796     35 1970-07-26 11:48:00  1970      7            6    11   \n",
       "28644887     12 1971-04-26 02:29:00  1971      4            0     2   \n",
       "28755646     52 1971-02-10 06:44:00  1971      2            2     6   \n",
       "5208006      25 1971-05-10 22:18:00  1971      5            0    22   \n",
       "\n",
       "          day_of_year  \n",
       "1320825           127  \n",
       "27814796          207  \n",
       "28644887          116  \n",
       "28755646           41  \n",
       "5208006           130  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def numerical_feature_preprocess(continuous_features,train,test,val):\n",
    "    scaler = StandardScaler()\n",
    "    for col in continuous_features:\n",
    "        #print train[col].head()\n",
    "        scaler.fit(train[col])\n",
    "        train[col] = scaler.transform(train[col])\n",
    "        test[col] = scaler.transform(test[col])\n",
    "        val[col] = scaler.transform(val[col])\n",
    "def categorical_feature_preprocess(categorical_feature,dataset):\n",
    "    list_categorical = []\n",
    "    for col in categorical_feature:\n",
    "        dummy = pd.get_dummies(dataset[col])\n",
    "        list_categorical.append(dummy)\n",
    "    dataset_categorical = pd.concat(list_categorical,axis=1)\n",
    "    return dataset_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
    "def modelfit(alg, dtrain, predictors,dtest,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        #print dtrain['place_encoded'].nunique()\n",
    "        xgb_param['num_class'] = dtrain['place_encoded'].nunique()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain['place_encoded'].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\\\n",
    "            metrics=['mlogloss'], early_stopping_rounds=early_stopping_rounds, show_progress=False)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain['place_encoded'],eval_metric='mlogloss')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "    \n",
    "        \n",
    "    #Print model report:\n",
    "    print \"\\nModel Report\"\n",
    "    print \"Accuracy (Train): %.4g\" % metrics.accuracy_score(dtrain['place_encoded'].values, dtrain_predictions)\n",
    "    #print \"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain['place_encoded'], dtrain_predprob)\n",
    "    #feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    #feat_imp.plot(kind='bar', title='Feature Importances (Train)')\n",
    "    #plt.ylabel('Train Feature Importance Score')\n",
    "    \n",
    "    test_prediction = alg.predict_proba(dtest[predictors])\n",
    "    return test_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_cell(train_data,val_data,test_data):\n",
    "    place_encoded = LabelEncoder()\n",
    "    place_encoded.fit(train_data[\"place_id\"])\n",
    "    train_data[\"place_encoded\"] = place_encoded.transform(train_data[\"place_id\"])\n",
    "    #val_data[\"place_encoded\"] = place_encoded.transform(val_data[\"place_id\"])\n",
    "\n",
    "    #categorical_features = [\"day_of_week\"]\n",
    "    numerical_feature_preprocess(continuous_features,train_data,test_data,val_data)\n",
    "    #train_categorical = categorical_feature_preprocess(categorical_features,train_data)\n",
    "    #test_categorical = categorical_feature_preprocess(categorical_features,test_data)\n",
    "    #val_categorical = categorical_feature_preprocess(categorical_features,val_data)\n",
    "    # print train_categorical.head()\n",
    "    # print test_categorical.head()\n",
    "    #train_data_processed = pd.concat([train_data[continuous_features],train_categorical],axis = 1)\n",
    "    #test_data_processed = pd.concat([test_data[continuous_features],test_categorical],axis = 1)\n",
    "    #val_data_processed = pd.concat([val_data[continuous_features],val_categorical],axis = 1)\n",
    "    xgb = XGBClassifier(learning_rate = 0.01,n_estimators = 1000, max_depth = 4, min_child_weight = 6, gamma = 0,\\\n",
    "                        subsample = 0.8, colsample_bytree=0.8,reg_alpha=0.005,objective= 'multi:softprob',\\\n",
    "                        nthread=4, scale_pos_weight=1, seed=27)\n",
    "    test_prediction = modelfit(xgb,train_data,continuous_features,test_data)\n",
    "    #knn.fit(train_data[continuous_features],train_data[\"place_encoded\"])\n",
    "    #train_accuracy = np.mean(train_data[\"place_encoded\"] == knn.predict(train_data[continuous_features]))\n",
    "    #val_accuracy = np.mean(val_data[\"place_encoded\"]== knn.predict(val_data[continuous_features]))\n",
    "    #train_log_loss = log_loss(train_data[\"place_encoded\"],np.array(knn.predict_proba(train_data[continuous_features])))\n",
    "    #print \"shape val_log_loss\", val_data_processed.shape\n",
    "    #print \"shape val_data\", val_data.shape\n",
    "    #val_log_loss = log_loss(val_data[\"place_encoded\"],np.array(knn.predict_proba(val_data_processed)))\n",
    "\n",
    "    #print train_data_processed.shape\n",
    "\n",
    "    #test_prediction = knn.predict_proba(test_data[continuous_features])\n",
    "    pred_labels = place_encoded.inverse_transform(np.argsort(test_prediction, axis=1)[:,::-1][:,:3]) \n",
    "    return pred_labels#test_prediction,pred_labels\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_grid(train_data,val_data,test_data,x_step,y_step,xy_range):\n",
    "    preds = np.zeros((test_data.shape[0], 3), dtype=np.int64)\n",
    "    #preds_val = np.zeros((val_data.shape[0],3),dtype=np.int64)\n",
    "    #print test_data.shape[0]\n",
    "    #train_accuracy = np.zeros((len(xy_range),len(xy_range)),dtype=float)\n",
    "    #val_accuracy = np.zeros((len(xy_range),len(xy_range)),dtype=float)\n",
    "    #train_log_loss = np.zeros((len(xy_range),len(xy_range)),dtype=float)\n",
    "    #val_log_loss = np.zeros((len(xy_range),len(xy_range)),dtype=float)\n",
    "    i, j = 0, 0\n",
    "    for x in xy_range:\n",
    "        j = 0\n",
    "        for y in xy_range:\n",
    "            train_data_cell = train_data.loc[(train_data[\"x\"] >= (x-x_step)) & (train_data[\"x\"] <= (x)) & (train_data[\"y\"] >= (y-y_step)) & (train_data[\"y\"] <= (y))] \n",
    "            # print train_data_cell.head()\n",
    "            test_data_cell = test_data.loc[(test_data[\"x\"] >= (x-x_step)) & (test_data[\"x\"] <= (x)) & (test_data[\"y\"] >= (y-y_step)) & (test_data[\"y\"] <= (y))] \n",
    "            val_data_cell = val_data.loc[(val_data[\"x\"] >= (x-x_step)) & (val_data[\"x\"] <= (x)) & (val_data[\"y\"] >= (y-y_step)) & (val_data[\"y\"] <= (y))]\n",
    "            \n",
    "            row_ids = test_data_cell.index\n",
    "            row_ids_val = val_data_cell.index\n",
    "            pred_labels = process_cell(train_data_cell,val_data_cell,test_data_cell)\n",
    "            #print max(row_ids)\n",
    "            #print test_data.shape\n",
    "            preds[row_ids] = pred_labels\n",
    "            # print x,y\n",
    "            # print i,j\n",
    "            j += 1\n",
    "        i += 1\n",
    "    pre_result = pd.DataFrame(preds,dtype = str,columns=[\"l1\",\"l2\",\"l3\"])\n",
    "    result = pre_result.l1.str.cat([pre_result.l2,pre_result.l3],sep = \" \")\n",
    "    result.name = \"place_id\"\n",
    "    result.to_csv(\"fb_checkin.csv\",index=True, header=True, index_label = \"row_id\")\n",
    "    #print result.head()\n",
    "    #print train_accuracy\n",
    "    #print train_log_loss\n",
    "    return result\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until cv error hasn't decreased in 50 rounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy (Train): 0.6791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until cv error hasn't decreased in 50 rounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy (Train): 0.6412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until cv error hasn't decreased in 50 rounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy (Train): 0.6652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until cv error hasn't decreased in 50 rounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy (Train): 0.6575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until cv error hasn't decreased in 50 rounds.\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/Users/ChiYuan/Documents/python/Kaggle/Facebook Checkin/\"\n",
    "continuous_features = [\"x\",\"y\",\"time\",\"year\",\"month\",\"hour\",\"day_of_year\",\"day_of_week\",\"accuracy\"]\n",
    "x_step = 0.5\n",
    "y_step = 0.5\n",
    "xy_range = np.linspace(0.5, 10.0, 20)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "test_data = test_data.reset_index(drop=True)\n",
    "val_data = val_data.reset_index(drop=True)\n",
    "result = process_grid(train_data,val_data,test_data,x_step,y_step,xy_range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#result.to_csv(file_path+\"fb_checkin.csv\",index=True, header=True, index_label = \"row_id\")\n",
    "    #print result.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
