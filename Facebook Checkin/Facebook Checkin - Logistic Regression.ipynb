{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114610490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests, zipfile, StringIO\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import log_loss\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "import seaborn as sns\n",
    "# Plotting Options\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "from IPython.core.debugger import Tracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_csv_zip(filename):\n",
    "    z = zipfile.ZipFile(filename+'.zip')\n",
    "    df = pd.read_csv(z.open(filename),index_col=False)\n",
    "    return df\n",
    "train = read_csv_zip(\"train.csv\")\n",
    "test = read_csv_zip(\"test.csv\")\n",
    "train_sample = train.sample(frac=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_datetime(df):\n",
    "    df[\"time_dt\"] = pd.to_datetime(df[\"time\"]*60,unit='s')\n",
    "    df[\"year\"] = df[\"time_dt\"].apply( lambda x : x.year)\n",
    "    df[\"month\"] = df[\"time_dt\"].apply( lambda x : x.month)\n",
    "    df[\"day_of_week\"] = df[\"time_dt\"].apply( lambda x: x.weekday())\n",
    "    df[\"hour\"] = df[\"time_dt\"].apply( lambda x: x.hour)\n",
    "    df[\"day_of_year\"] = df[\"time_dt\"].apply( lambda x: x.dayofyear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sample= train.sample(frac=0.1) #switch to full training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sample = test.sample(frac=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = test\n",
    "msk = np.random.rand(len(train_sample)) < 0.8\n",
    "train_data = train_sample[msk]\n",
    "val_data = train_sample[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_datetime(train_data)\n",
    "get_datetime(test_data)\n",
    "get_datetime(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "      <th>place_id</th>\n",
       "      <th>time_dt</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4637094</th>\n",
       "      <td>4637094</td>\n",
       "      <td>5.0612</td>\n",
       "      <td>3.7029</td>\n",
       "      <td>71</td>\n",
       "      <td>528316</td>\n",
       "      <td>4424198123</td>\n",
       "      <td>1971-01-02 21:16:00</td>\n",
       "      <td>1971</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267449</th>\n",
       "      <td>267449</td>\n",
       "      <td>6.1940</td>\n",
       "      <td>8.6268</td>\n",
       "      <td>887</td>\n",
       "      <td>694757</td>\n",
       "      <td>3753826348</td>\n",
       "      <td>1971-04-28 11:17:00</td>\n",
       "      <td>1971</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4037015</th>\n",
       "      <td>4037015</td>\n",
       "      <td>9.5382</td>\n",
       "      <td>1.8987</td>\n",
       "      <td>47</td>\n",
       "      <td>650797</td>\n",
       "      <td>6151709843</td>\n",
       "      <td>1971-03-28 22:37:00</td>\n",
       "      <td>1971</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429266</th>\n",
       "      <td>429266</td>\n",
       "      <td>1.2203</td>\n",
       "      <td>2.5641</td>\n",
       "      <td>10</td>\n",
       "      <td>120233</td>\n",
       "      <td>2355236719</td>\n",
       "      <td>1970-03-25 11:53:00</td>\n",
       "      <td>1970</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6154220</th>\n",
       "      <td>6154220</td>\n",
       "      <td>8.0659</td>\n",
       "      <td>4.9045</td>\n",
       "      <td>69</td>\n",
       "      <td>116720</td>\n",
       "      <td>4835025077</td>\n",
       "      <td>1970-03-23 01:20:00</td>\n",
       "      <td>1970</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          row_id       x       y  accuracy    time    place_id  \\\n",
       "4637094  4637094  5.0612  3.7029        71  528316  4424198123   \n",
       "267449    267449  6.1940  8.6268       887  694757  3753826348   \n",
       "4037015  4037015  9.5382  1.8987        47  650797  6151709843   \n",
       "429266    429266  1.2203  2.5641        10  120233  2355236719   \n",
       "6154220  6154220  8.0659  4.9045        69  116720  4835025077   \n",
       "\n",
       "                    time_dt  year  month  day_of_week  hour  day_of_year  \n",
       "4637094 1971-01-02 21:16:00  1971      1            5    21            2  \n",
       "267449  1971-04-28 11:17:00  1971      4            2    11          118  \n",
       "4037015 1971-03-28 22:37:00  1971      3            6    22           87  \n",
       "429266  1970-03-25 11:53:00  1970      3            2    11           84  \n",
       "6154220 1970-03-23 01:20:00  1970      3            0     1           82  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def numerical_feature_preprocess(continuous_features,train,test,val):\n",
    "    scaler = StandardScaler()\n",
    "    for col in continuous_features:\n",
    "        #print train[col].head()\n",
    "        scaler.fit(train[col])\n",
    "        train[col] = scaler.transform(train[col])*fw[col]\n",
    "        test[col] = scaler.transform(test[col])*fw[col]\n",
    "        val[col] = scaler.transform(val[col])*fw[col]\n",
    "def categorical_feature_preprocess(categorical_feature,dataset):\n",
    "    list_categorical = []\n",
    "    for col in categorical_feature:\n",
    "        dummy = pd.get_dummies(dataset[col])\n",
    "        list_categorical.append(dummy)\n",
    "    dataset_categorical = pd.concat(list_categorical,axis=1)\n",
    "    return dataset_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_cell(train_data,val_data,test_data):\n",
    "    place_encoded = LabelEncoder()\n",
    "    place_encoded.fit(train_data[\"place_id\"].append(val_data[\"place_id\"]))\n",
    "    train_data[\"place_encoded\"] = place_encoded.transform(train_data[\"place_id\"])\n",
    "    val_data[\"place_encoded\"] = place_encoded.transform(val_data[\"place_id\"])\n",
    "\n",
    "    #categorical_features = [\"day_of_week\"]\n",
    "    numerical_feature_preprocess(continuous_features,train_data,test_data,val_data)\n",
    "    #train_categorical = categorical_feature_preprocess(categorical_features,train_data)\n",
    "    #test_categorical = categorical_feature_preprocess(categorical_features,test_data)\n",
    "    #val_categorical = categorical_feature_preprocess(categorical_features,val_data)\n",
    "    # print train_categorical.head()\n",
    "    # print test_categorical.head()\n",
    "    #train_data_processed = pd.concat([train_data[continuous_features],train_categorical],axis = 1)\n",
    "    #test_data_processed = pd.concat([test_data[continuous_features],test_categorical],axis = 1)\n",
    "    #val_data_processed = pd.concat([val_data[continuous_features],val_categorical],axis = 1)\n",
    "    \n",
    "    lg = LogisticRegression(random_state=20)\n",
    "    lg.fit(train_data[continuous_features],train_data[\"place_encoded\"])\n",
    "    train_accuracy = np.mean(train_data[\"place_encoded\"] == lg.predict(train_data[continuous_features]))\n",
    "    val_accuracy = np.mean(val_data[\"place_encoded\"]== lg.predict(val_data[continuous_features]))\n",
    "    train_log_loss = log_loss(train_data[\"place_encoded\"],np.array(lg.predict_proba(train_data[continuous_features])))\n",
    "    #print \"shape val_log_loss\", val_data_processed.shape\n",
    "    #print \"shape val_data\", val_data.shape\n",
    "    #val_log_loss = log_loss(val_data[\"place_encoded\"],np.array(lg.predict_proba(val_data_processed)))\n",
    "\n",
    "    #print train_data_processed.shape\n",
    "\n",
    "    test_prediction = lg.predict_proba(test_data[continuous_features])\n",
    "    pred_labels = place_encoded.inverse_transform(np.argsort(test_prediction, axis=1)[:,::-1][:,:3]) \n",
    "    return pred_labels,train_accuracy,train_log_loss,val_accuracy #test_prediction,pred_labels\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def process_grid(train_data,val_data,test_data,x_step,y_step,xy_range):\n",
    "    preds = np.zeros((test_data.shape[0], 3), dtype=np.int64)\n",
    "    #preds_val = np.zeros((val_data.shape[0],3),dtype=np.int64)\n",
    "    #print test_data.shape[0]\n",
    "    train_accuracy = np.zeros((len(xy_range),len(xy_range)),dtype=float)\n",
    "    val_accuracy = np.zeros((len(xy_range),len(xy_range)),dtype=float)\n",
    "    train_log_loss = np.zeros((len(xy_range),len(xy_range)),dtype=float)\n",
    "    val_log_loss = np.zeros((len(xy_range),len(xy_range)),dtype=float)\n",
    "    i, j = 0, 0\n",
    "    for x in xy_range:\n",
    "        j = 0\n",
    "        for y in xy_range:\n",
    "            train_data_cell = train_data.loc[(train_data[\"x\"] >= (x-x_step)) & (train_data[\"x\"] <= (x)) & (train_data[\"y\"] >= (y-y_step)) & (train_data[\"y\"] <= (y))] \n",
    "            # print train_data_cell.head()\n",
    "            test_data_cell = test_data.loc[(test_data[\"x\"] >= (x-x_step)) & (test_data[\"x\"] <= (x)) & (test_data[\"y\"] >= (y-y_step)) & (test_data[\"y\"] <= (y))] \n",
    "            val_data_cell = val_data.loc[(val_data[\"x\"] >= (x-x_step)) & (val_data[\"x\"] <= (x)) & (val_data[\"y\"] >= (y-y_step)) & (val_data[\"y\"] <= (y))]\n",
    "            \n",
    "            row_ids = test_data_cell.index\n",
    "            row_ids_val = val_data_cell.index\n",
    "            pred_labels,train_accuracy[i,j],train_log_loss[i,j],val_accuracy[i,j] = process_cell(train_data_cell,val_data_cell,test_data_cell)\n",
    "            #print max(row_ids)\n",
    "            #print test_data.shape\n",
    "            preds[row_ids] = pred_labels\n",
    "            # print x,y\n",
    "            # print i,j\n",
    "            j += 1\n",
    "        i += 1\n",
    "    pre_result = pd.DataFrame(preds,dtype = str,columns=[\"l1\",\"l2\",\"l3\"])\n",
    "    result = pre_result.l1.str.cat([pre_result.l2,pre_result.l3],sep = \" \")\n",
    "    result.name = \"place_id\"\n",
    "    #result.to_csv(\"fb_checkin.csv\",index=True, header=True, index_label = \"row_id\")\n",
    "    #print result.head()\n",
    "    #print train_accuracy\n",
    "    #print train_log_loss\n",
    "    return result,train_accuracy,train_log_loss,val_accuracy\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_path = \"/Users/ChiYuan/Documents/python/Kaggle/Facebook Checkin/\"\n",
    "continuous_features = [\"x\",\"y\",\"time\",\"year\",\"month\",\"hour\",\"day_of_year\",\"day_of_week\",\"accuracy\"]\n",
    "#weight for [\"x\",\"y\",\"time\",\"year\",\"month\",\"hour\",\"day_of_year\",\"day_of_week\",\"accuracy\"]\n",
    "fw = {\"x\":1,\"y\":2,\"time\":0.5,\"year\":0.5,\"month\":0.5,\"hour\":0.5,\"day_of_year\":0.2,\"day_of_week\":0.5,\"accuracy\":0.1} #wait is apply after each feature is transformed by standard deviation\n",
    "x_step = 0.5\n",
    "y_step = 0.5\n",
    "xy_range = np.linspace(0.5, 10.0, 20)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "test_data = test_data.reset_index(drop=True)\n",
    "val_data = val_data.reset_index(drop=True)\n",
    "result,train_accuracy,train_log_loss,val_accuracy = process_grid(train_data,val_data,test_data,x_step,y_step,xy_range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.17780503,  0.16553288,  0.16619519,  0.17525126,  0.16015375,\n",
       "         0.196793  ,  0.1661195 ,  0.18187919,  0.17280453,  0.1719697 ,\n",
       "         0.16582187,  0.2115942 ,  0.18012924,  0.19554849,  0.18838174,\n",
       "         0.1813054 ,  0.16240725,  0.14037433,  0.19373777,  0.183687  ],\n",
       "       [ 0.16081871,  0.18044515,  0.16918647,  0.16145181,  0.15826331,\n",
       "         0.16242822,  0.18309859,  0.1595359 ,  0.16131026,  0.160401  ,\n",
       "         0.15251799,  0.15424165,  0.18215339,  0.18780096,  0.17937545,\n",
       "         0.15427658,  0.1663067 ,  0.16049383,  0.17156528,  0.16741214],\n",
       "       [ 0.17873754,  0.19859813,  0.15147625,  0.14183381,  0.15529248,\n",
       "         0.15268558,  0.16970138,  0.18539326,  0.14371257,  0.13560454,\n",
       "         0.17044674,  0.17777778,  0.16065574,  0.12953368,  0.16690751,\n",
       "         0.16838906,  0.17747164,  0.16224189,  0.15946844,  0.15801024],\n",
       "       [ 0.19754867,  0.1673699 ,  0.15825688,  0.17238913,  0.15250696,\n",
       "         0.157277  ,  0.15896359,  0.1663286 ,  0.14830814,  0.16764706,\n",
       "         0.16654855,  0.17052023,  0.14739884,  0.16796641,  0.16507001,\n",
       "         0.18047337,  0.15926396,  0.13858696,  0.17022654,  0.14502307],\n",
       "       [ 0.15238095,  0.17396184,  0.15941176,  0.14890282,  0.1659751 ,\n",
       "         0.18729747,  0.15127841,  0.19775421,  0.16954787,  0.130674  ,\n",
       "         0.2033543 ,  0.15102975,  0.16548798,  0.18630678,  0.15090403,\n",
       "         0.17346182,  0.14836224,  0.16165665,  0.18115942,  0.16573557],\n",
       "       [ 0.17423231,  0.17835671,  0.16466346,  0.15138282,  0.18928789,\n",
       "         0.16580012,  0.15560166,  0.15728022,  0.15418502,  0.16163522,\n",
       "         0.1469583 ,  0.18301514,  0.17154812,  0.1618929 ,  0.16204691,\n",
       "         0.15155061,  0.15969317,  0.16918429,  0.13720485,  0.14879792],\n",
       "       [ 0.16595442,  0.14966985,  0.15960912,  0.16967509,  0.14843206,\n",
       "         0.17792642,  0.15038168,  0.15349144,  0.1496063 ,  0.13023952,\n",
       "         0.16877919,  0.14945848,  0.15631692,  0.16107872,  0.15891473,\n",
       "         0.18649733,  0.16280702,  0.14783282,  0.15870881,  0.16759388],\n",
       "       [ 0.15831987,  0.19208211,  0.1669967 ,  0.17025712,  0.18367347,\n",
       "         0.15608108,  0.17382413,  0.13532856,  0.17651147,  0.17317073,\n",
       "         0.18879056,  0.16642442,  0.18448023,  0.13496933,  0.15231317,\n",
       "         0.18528252,  0.16614616,  0.14901712,  0.14904187,  0.1746784 ],\n",
       "       [ 0.19337017,  0.14457831,  0.13148543,  0.16212625,  0.16771488,\n",
       "         0.14989444,  0.15287049,  0.17414248,  0.17413249,  0.15347885,\n",
       "         0.12926829,  0.1669627 ,  0.15505464,  0.18761966,  0.19848901,\n",
       "         0.14756258,  0.1504065 ,  0.16347469,  0.17115097,  0.16784203],\n",
       "       [ 0.14295439,  0.14020619,  0.15117057,  0.1547619 ,  0.15483871,\n",
       "         0.18945177,  0.15939957,  0.16131237,  0.16133829,  0.15910677,\n",
       "         0.13278008,  0.15975936,  0.16525147,  0.15684774,  0.18113772,\n",
       "         0.16239892,  0.14931507,  0.17429577,  0.13642053,  0.1406564 ],\n",
       "       [ 0.16196674,  0.16564417,  0.16259678,  0.1740675 ,  0.15423977,\n",
       "         0.14757282,  0.14919355,  0.17548077,  0.15144083,  0.19112988,\n",
       "         0.15      ,  0.20096022,  0.1713555 ,  0.14227642,  0.18566553,\n",
       "         0.17948718,  0.17767988,  0.14509068,  0.14120668,  0.14681648],\n",
       "       [ 0.14235624,  0.12278107,  0.15225806,  0.17706821,  0.16591252,\n",
       "         0.17691154,  0.1546536 ,  0.18436155,  0.13694461,  0.13069307,\n",
       "         0.14064698,  0.15934844,  0.16964286,  0.14939024,  0.1627095 ,\n",
       "         0.13713592,  0.16981132,  0.17472598,  0.1219716 ,  0.16819572],\n",
       "       [ 0.14030612,  0.15363512,  0.15884477,  0.13371266,  0.17142857,\n",
       "         0.18043026,  0.16909217,  0.16351249,  0.20780781,  0.16815989,\n",
       "         0.16524438,  0.18248175,  0.18577649,  0.15128383,  0.16391437,\n",
       "         0.15098039,  0.14051355,  0.17956853,  0.16814159,  0.17590206],\n",
       "       [ 0.14533623,  0.16643357,  0.14979757,  0.1340861 ,  0.18533605,\n",
       "         0.14395393,  0.16826568,  0.15209911,  0.16270567,  0.16654492,\n",
       "         0.13165906,  0.15389972,  0.15903141,  0.13741412,  0.15416098,\n",
       "         0.1744868 ,  0.15409004,  0.14713542,  0.14889197,  0.16243655],\n",
       "       [ 0.16595442,  0.15176471,  0.17498243,  0.1516129 ,  0.14322088,\n",
       "         0.14852151,  0.15748031,  0.16809816,  0.16839917,  0.13667285,\n",
       "         0.16127024,  0.15978695,  0.19767442,  0.1648664 ,  0.1754594 ,\n",
       "         0.15749656,  0.16061047,  0.19041614,  0.13955224,  0.17867232],\n",
       "       [ 0.17061021,  0.17666891,  0.18660969,  0.17457421,  0.1652459 ,\n",
       "         0.16966967,  0.17757009,  0.17840376,  0.14399093,  0.15496521,\n",
       "         0.17566595,  0.14555766,  0.20042949,  0.15845697,  0.16335682,\n",
       "         0.17708333,  0.16078431,  0.14729242,  0.16481775,  0.15581204],\n",
       "       [ 0.17484009,  0.14109091,  0.17764471,  0.16446912,  0.17376831,\n",
       "         0.19848901,  0.1266209 ,  0.16234756,  0.19775596,  0.14202476,\n",
       "         0.14845516,  0.14658926,  0.1619883 ,  0.17832388,  0.16776076,\n",
       "         0.17885679,  0.14439655,  0.13101406,  0.15153538,  0.19174603],\n",
       "       [ 0.13299784,  0.16326531,  0.17071525,  0.14002732,  0.17085077,\n",
       "         0.15739385,  0.19586105,  0.16043614,  0.15754779,  0.15571155,\n",
       "         0.17356475,  0.17549897,  0.15379665,  0.15282624,  0.1472973 ,\n",
       "         0.16071429,  0.18291863,  0.14697802,  0.14407989,  0.16644737],\n",
       "       [ 0.18266434,  0.15384615,  0.16141996,  0.19057239,  0.18257261,\n",
       "         0.14366197,  0.18667699,  0.16199158,  0.16105941,  0.19815668,\n",
       "         0.17446177,  0.17447496,  0.16045845,  0.15211063,  0.17561299,\n",
       "         0.15690867,  0.16399417,  0.15727209,  0.17779204,  0.18812589],\n",
       "       [ 0.19904567,  0.18204489,  0.16609589,  0.14637073,  0.20317726,\n",
       "         0.17133758,  0.20518519,  0.18816821,  0.15443213,  0.16238723,\n",
       "         0.21534847,  0.18011958,  0.16953317,  0.19894598,  0.19556714,\n",
       "         0.19312602,  0.1965812 ,  0.1504788 ,  0.20265549,  0.17924528]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.20233645,  0.19209576,  0.2012963 ,  0.19235794,  0.18149524,\n",
       "         0.21189265,  0.18988983,  0.20108505,  0.19438559,  0.1978022 ,\n",
       "         0.19728507,  0.21304586,  0.19429134,  0.21615889,  0.2153059 ,\n",
       "         0.20916092,  0.18222482,  0.17265434,  0.21843854,  0.19837047],\n",
       "       [ 0.18562232,  0.21015348,  0.19006479,  0.1863306 ,  0.1747473 ,\n",
       "         0.19280311,  0.18007025,  0.19641907,  0.17710168,  0.20022753,\n",
       "         0.18342887,  0.19504542,  0.19250577,  0.18526877,  0.18561312,\n",
       "         0.19781962,  0.18365142,  0.18318318,  0.19071251,  0.18442895],\n",
       "       [ 0.20234899,  0.20235383,  0.17231076,  0.16571952,  0.19092146,\n",
       "         0.18054692,  0.18172502,  0.20201159,  0.18229694,  0.16339869,\n",
       "         0.18188252,  0.20301304,  0.17823156,  0.15629602,  0.19021837,\n",
       "         0.191833  ,  0.19411421,  0.19800269,  0.15907591,  0.19565621],\n",
       "       [ 0.20326332,  0.19158323,  0.18397018,  0.19279846,  0.17282025,\n",
       "         0.18736802,  0.19705992,  0.16423796,  0.17002629,  0.16917225,\n",
       "         0.17160473,  0.19738587,  0.16894806,  0.17776804,  0.18211091,\n",
       "         0.18486371,  0.17650845,  0.15658861,  0.17288191,  0.171875  ],\n",
       "       [ 0.18986239,  0.17991692,  0.16581556,  0.17573719,  0.16750477,\n",
       "         0.19044712,  0.17973399,  0.21863743,  0.19280936,  0.15469811,\n",
       "         0.18970737,  0.15935951,  0.18088131,  0.19437115,  0.18246721,\n",
       "         0.18948323,  0.16584198,  0.18762757,  0.19238416,  0.18817457],\n",
       "       [ 0.186882  ,  0.19748306,  0.18494096,  0.16345441,  0.18968204,\n",
       "         0.1899985 ,  0.17497474,  0.17584279,  0.17286786,  0.1641791 ,\n",
       "         0.16139023,  0.20363576,  0.17901999,  0.18260188,  0.16604906,\n",
       "         0.17062878,  0.18894952,  0.18989626,  0.15828041,  0.17138131],\n",
       "       [ 0.18507139,  0.18300423,  0.16320817,  0.17718909,  0.18437444,\n",
       "         0.18332785,  0.16544875,  0.17633136,  0.18956137,  0.15489081,\n",
       "         0.18854569,  0.16545718,  0.17696131,  0.16351757,  0.19653956,\n",
       "         0.19320244,  0.17618803,  0.1690733 ,  0.16902357,  0.1827385 ],\n",
       "       [ 0.18543046,  0.19929763,  0.1822445 ,  0.18665757,  0.19374499,\n",
       "         0.17715736,  0.18621701,  0.15019317,  0.20449236,  0.1791587 ,\n",
       "         0.19544907,  0.1814093 ,  0.20113852,  0.15468016,  0.17289298,\n",
       "         0.19113787,  0.16946088,  0.17175513,  0.16447012,  0.19403715],\n",
       "       [ 0.19886792,  0.19218188,  0.1903313 ,  0.17222402,  0.18414834,\n",
       "         0.17977528,  0.18008835,  0.17186495,  0.18468539,  0.16717001,\n",
       "         0.15607625,  0.18230643,  0.17799027,  0.18439716,  0.20381021,\n",
       "         0.1635569 ,  0.18765476,  0.18183403,  0.16572077,  0.1773331 ],\n",
       "       [ 0.18412754,  0.17764371,  0.17285443,  0.16126158,  0.17670465,\n",
       "         0.21016052,  0.1919363 ,  0.17620098,  0.19406077,  0.1712049 ,\n",
       "         0.16698162,  0.17643063,  0.19544365,  0.17858494,  0.20556358,\n",
       "         0.19318575,  0.17405925,  0.18497456,  0.15511145,  0.15930435],\n",
       "       [ 0.1856454 ,  0.16862613,  0.18100673,  0.18671533,  0.18125   ,\n",
       "         0.1701265 ,  0.16828266,  0.21286831,  0.1569553 ,  0.20451492,\n",
       "         0.17563694,  0.20815847,  0.18821199,  0.15793835,  0.19546048,\n",
       "         0.19432314,  0.19238095,  0.17997166,  0.1606251 ,  0.17369773],\n",
       "       [ 0.16956738,  0.14825688,  0.17337716,  0.19280866,  0.16701984,\n",
       "         0.19195046,  0.19186347,  0.19537739,  0.16959342,  0.16043307,\n",
       "         0.16330984,  0.18205041,  0.17688889,  0.16043426,  0.18605511,\n",
       "         0.16343017,  0.18515314,  0.17880577,  0.15292663,  0.16543521],\n",
       "       [ 0.17870008,  0.18247405,  0.17506121,  0.16430446,  0.16643741,\n",
       "         0.19500335,  0.18863362,  0.17295426,  0.2016677 ,  0.19216848,\n",
       "         0.19144565,  0.18686188,  0.19992782,  0.17742213,  0.18012999,\n",
       "         0.1690549 ,  0.17088608,  0.18765153,  0.1870229 ,  0.18635089],\n",
       "       [ 0.1687293 ,  0.1921757 ,  0.17567568,  0.15265985,  0.19859853,\n",
       "         0.17231398,  0.17917723,  0.18334825,  0.17324425,  0.18307582,\n",
       "         0.16899469,  0.18145232,  0.1981227 ,  0.17377156,  0.17920354,\n",
       "         0.18647133,  0.17001979,  0.16957063,  0.16971545,  0.18379775],\n",
       "       [ 0.17280027,  0.18093239,  0.18276668,  0.19215622,  0.17544149,\n",
       "         0.16886367,  0.17417663,  0.18274035,  0.19821188,  0.16960524,\n",
       "         0.17894905,  0.16221152,  0.20678571,  0.18398876,  0.18967859,\n",
       "         0.17208481,  0.18824378,  0.19787557,  0.16180049,  0.21245484],\n",
       "       [ 0.21033616,  0.19705493,  0.19162956,  0.16764343,  0.17834804,\n",
       "         0.18098511,  0.19287246,  0.18806659,  0.16738996,  0.17011052,\n",
       "         0.20674725,  0.15910564,  0.19244288,  0.17303973,  0.18366074,\n",
       "         0.18181818,  0.18091779,  0.15923452,  0.17999204,  0.17557861],\n",
       "       [ 0.20332916,  0.1749503 ,  0.20799866,  0.19224197,  0.18546069,\n",
       "         0.20970774,  0.15670911,  0.19627235,  0.21189722,  0.19018182,\n",
       "         0.17682582,  0.17440402,  0.16407523,  0.19760479,  0.17394366,\n",
       "         0.19035683,  0.16467226,  0.15820842,  0.17993604,  0.21190437],\n",
       "       [ 0.17243867,  0.17175288,  0.18838146,  0.16663684,  0.18020348,\n",
       "         0.17307692,  0.19480287,  0.1810129 ,  0.17546362,  0.18493946,\n",
       "         0.18096925,  0.20111543,  0.15532932,  0.16769175,  0.17737572,\n",
       "         0.18983402,  0.19049943,  0.16518977,  0.15699537,  0.18984656],\n",
       "       [ 0.19103343,  0.1894387 ,  0.19822237,  0.18476096,  0.20780856,\n",
       "         0.17786353,  0.19966443,  0.17883008,  0.18847162,  0.19341723,\n",
       "         0.18888057,  0.17866248,  0.17330211,  0.19167121,  0.18883333,\n",
       "         0.19311263,  0.17899128,  0.18098361,  0.19135503,  0.20110833],\n",
       "       [ 0.21543242,  0.2212656 ,  0.17482939,  0.16753286,  0.20190212,\n",
       "         0.18062397,  0.21353185,  0.19892173,  0.18471111,  0.19885774,\n",
       "         0.22487223,  0.20971302,  0.20102282,  0.19643741,  0.20337334,\n",
       "         0.22387443,  0.22170947,  0.18660458,  0.22846574,  0.21297539]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result.to_csv(file_path+\"fb_checkin.csv\",index=True, header=True, index_label = \"row_id\")\n",
    "    #print result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print xy_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
