{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import skimage.feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose,Permute,Reshape,Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.set_image_dim_ordering('tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = '/Users/chiyuan/Documents/learning/kaggle/sea_lion/TrainSmall2/Train/'\n",
    "TRAIN_GT_PATH = '/Users/chiyuan/Documents/learning/kaggle/sea_lion/TrainSmall2/TrainDotted/'\n",
    "TRAIN_FILENAMES = [item for item in os.listdir(TRAIN_PATH) if not item.startswith('.')]\n",
    "TRAIN_FILENAMES = sorted(TRAIN_FILENAMES, key = lambda item: int(item.partition('.')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['41.jpg',\n",
       " '42.jpg',\n",
       " '43.jpg',\n",
       " '44.jpg',\n",
       " '45.jpg',\n",
       " '46.jpg',\n",
       " '47.jpg',\n",
       " '48.jpg',\n",
       " '49.jpg',\n",
       " '50.jpg']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_FILENAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_images = len(TRAIN_FILENAMES)\n",
    "image_row, image_col = 512, 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_cat = 5\n",
    "def generate_image_and_gt(TRAIN_FILENAMES,TRAIN_PATH,TRAIN_GT_PATH,batch_size):\n",
    "    i = 0\n",
    "    while True:\n",
    "        random.shuffle(TRAIN_FILENAMES)\n",
    "        imgs = np.ndarray((batch_size,image_row,image_col,3),dtype=np.float32)\n",
    "        imgs_gt = np.ndarray((batch_size,image_row,image_col,num_cat),dtype=np.uint8)\n",
    "        for TRAIN_FILENAME in TRAIN_FILENAMES:\n",
    "            # in ground truth data, black out\n",
    "            # in ground truth data, black out\n",
    "\n",
    "            image = cv2.imread(TRAIN_PATH+TRAIN_FILENAME)\n",
    "            #image = cv2.resize(image,(image_row,image_col),interpolation = cv2.INTER_AREA)\n",
    "            image_gt = cv2.imread(TRAIN_GT_PATH+TRAIN_FILENAME)\n",
    "            #image_gt = cv2.resize(image,(image_row,image_col),interpolation = cv2.INTER_AREA)\n",
    "\n",
    "            image_mask = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "            image_mask[image_mask<20] = 0 \n",
    "            image_mask[image_mask>20] = 255\n",
    "\n",
    "            image_gt_mask = cv2.cvtColor(image_gt,cv2.COLOR_BGR2GRAY)\n",
    "            image_gt_mask[image_gt_mask<20] = 0 \n",
    "            image_gt_mask[image_gt_mask>20] = 255\n",
    "\n",
    "            image_diff = cv2.absdiff(image,image_gt)\n",
    "            image_diff = cv2.bitwise_or(image_diff,image_diff,mask=image_gt_mask)\n",
    "            image_diff = cv2.bitwise_or(image_diff,image_diff,mask=image_mask)\n",
    "            image_diff = cv2.cvtColor(image_diff,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            blobs = skimage.feature.blob_log(image_diff,min_sigma=3,max_sigma=4,num_sigma=1,threshold=0.02)\n",
    "            gt_data = np.zeros((image.shape[0],image.shape[1],5))\n",
    "            # gt_adult_male = np.zeros(image.shape)\n",
    "            # gt_subadult_male = np.zeros(image.shape)\n",
    "            # gt_pups = np.zeros(image.shape)\n",
    "            for blob in blobs:\n",
    "                y,x,s = blob\n",
    "                b,g,r = image[int(y)][int(x)][:]\n",
    "                if r > 200 and b < 50 and g < 50: # RED adult male\n",
    "                    gt_data[int(y),int(x),0] = 1  \n",
    "                elif r > 200 and b > 200 and g < 50: # MAGENTA subadult_males\n",
    "                    gt_data[int(y),int(x),1] = 1         \n",
    "                elif r < 100 and b < 100 and 150 < g < 200: # GREEN pups\n",
    "                    gt_data[int(y),int(x),2] = 1\n",
    "                elif r < 100 and  100 < b and g < 100: # BLUE juveniles\n",
    "                    gt_data[int(y),int(x),3] = 1\n",
    "                elif r < 150 and b < 50 and g < 100:  # BROWN adult_females\n",
    "                    gt_data[int(y),int(x),4] = 1\n",
    "            image = cv2.resize(image,(image_row,image_col),interpolation = cv2.INTER_AREA)\n",
    "            for cat in range(num_cat):\n",
    "                 imgs_gt[i,:,:,cat] = cv2.resize(gt_data[:,:,cat],(image_row,image_col))\n",
    "            #image = image.astype('float32')\n",
    "            imgs[i] = image#.transpose(2,0,1)\n",
    "            #imgs_gt[i] = gt_data\n",
    "            if i+1 == batch_size:\n",
    "                imgs-=np.mean(imgs)\n",
    "                imgs/=np.std(imgs)\n",
    "                print 'yield ',TRAIN_FILENAME\n",
    "                yield(imgs,imgs_gt.reshape(-1,image_row*image_col,num_cat))\n",
    "                imgs = np.ndarray((batch_size,image_row,image_col,3),dtype=np.float32)\n",
    "                imgs_gt = np.ndarray((batch_size,image_row,image_col,num_cat),dtype=np.uint8)\n",
    "                i = 0\n",
    "            else:\n",
    "                i += 1\n",
    "\n",
    "            #need to create a iternator if can't feet all images? \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils import to_categorical\n",
    "# y_train = to_ccategorical(np.random.randint(10, size=(1000, 1)), num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smooth = 1.\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "def get_unet():\n",
    "    inputs = Input((image_row, image_col, 3))\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "    \n",
    "    conv10 = Conv2D(num_cat, (1, 1))(inputs)\n",
    "    reshape1 = Reshape((image_row*image_col,num_cat))(conv10)\n",
    "    soft = Activation('softmax')(reshape1)\n",
    "    model = Model(inputs=[inputs], outputs=[soft])\n",
    "    \n",
    "    model.compile(optimizer=Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "\n",
    "# imgs = np.ndarray((num_images,image_row,image_col,3),dtype=np.float32)\n",
    "# imgs_gt = np.ndarray((num_images,image_row,image_col,num_cat),dtype=np.float32)\n",
    "# for TRAIN_FILENAME in TRAIN_FILENAMES:\n",
    "#     # in ground truth data, black out\n",
    "\n",
    "#     image = cv2.imread(TRAIN_PATH+TRAIN_FILENAME)\n",
    "#     #image = cv2.resize(image,(image_row,image_col),interpolation = cv2.INTER_AREA)\n",
    "#     image_gt = cv2.imread(TRAIN_GT_PATH+TRAIN_FILENAME)\n",
    "#     #image_gt = cv2.resize(image,(image_row,image_col),interpolation = cv2.INTER_AREA)\n",
    "\n",
    "#     image_mask = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "#     image_mask[image_mask<20] = 0 \n",
    "#     image_mask[image_mask>20] = 255\n",
    "\n",
    "#     image_gt_mask = cv2.cvtColor(image_gt,cv2.COLOR_BGR2GRAY)\n",
    "#     image_gt_mask[image_gt_mask<20] = 0 \n",
    "#     image_gt_mask[image_gt_mask>20] = 255\n",
    "\n",
    "#     image_diff = cv2.absdiff(image,image_gt)\n",
    "#     image_diff = cv2.bitwise_or(image_diff,image_diff,mask=image_gt_mask)\n",
    "#     image_diff = cv2.bitwise_or(image_diff,image_diff,mask=image_mask)\n",
    "#     image_diff = cv2.cvtColor(image_diff,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#     blobs = skimage.feature.blob_log(image_diff,min_sigma=3,max_sigma=4,num_sigma=1,threshold=0.02)\n",
    "#     gt_data = np.zeros((image.shape[0],image.shape[1],5))\n",
    "#     # gt_adult_male = np.zeros(image.shape)\n",
    "#     # gt_subadult_male = np.zeros(image.shape)\n",
    "#     # gt_pups = np.zeros(image.shape)\n",
    "#     for blob in blobs:\n",
    "#         y,x,s = blob\n",
    "#         b,g,r = image[int(y)][int(x)][:]\n",
    "#         if r > 200 and b < 50 and g < 50: # RED adult male\n",
    "#             gt_data[int(y),int(x),0] = 1  \n",
    "#         elif r > 200 and b > 200 and g < 50: # MAGENTA subadult_males\n",
    "#             gt_data[int(y),int(x),1] = 1         \n",
    "#         elif r < 100 and b < 100 and 150 < g < 200: # GREEN pups\n",
    "#             gt_data[int(y),int(x),2] = 1\n",
    "#         elif r < 100 and  100 < b and g < 100: # BLUE juveniles\n",
    "#             gt_data[int(y),int(x),3] = 1\n",
    "#         elif r < 150 and b < 50 and g < 100:  # BROWN adult_females\n",
    "#             gt_data[int(y),int(x),4] = 1\n",
    "#     image = cv2.resize(image,(image_row,image_col),interpolation = cv2.INTER_AREA)\n",
    "#     for cat in range(num_cat):\n",
    "#          imgs_gt[i,:,:,cat] = cv2.resize(gt_data[:,:,cat],(image_row,image_col))\n",
    "#     #image = image.astype('float32')\n",
    "#     imgs[i] = image#.transpose(2,0,1)\n",
    "#     #imgs_gt[i] = gt_data\n",
    "#     i += 1\n",
    "# imgs-=np.mean(imgs)\n",
    "# imgs/=np.std(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'imgs_gt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-01666a393a6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimgs_gt_reshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs_gt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_row\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mimage_col\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'imgs_gt' is not defined"
     ]
    }
   ],
   "source": [
    "#imgs_gt_reshape = imgs_gt.reshape(-1,image_row*image_col,num_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = get_unet()\n",
    "# model_fit = model.fit(imgs, imgs_gt_reshape, batch_size=32, nb_epoch=20, verbose=1, shuffle=True,\n",
    "#                validation_split=0.1)\n",
    "# #model.train_on_batch(imgs[:,:,:,[0]],imgs_gt[...,np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH2 = '/Users/chiyuan/Documents/learning/kaggle/sea_lion/KaggleNOAASeaLions/Train/'\n",
    "TRAIN_GT_PATH2 = '/Users/chiyuan/Documents/learning/kaggle/sea_lion/KaggleNOAASeaLions/TrainDotted/'\n",
    "TRAIN_FILENAMES2 = [item for item in os.listdir(TRAIN_PATH2) if not item.startswith('.')]\n",
    "random.seed(1)\n",
    "train_len_tot = len(TRAIN_FILENAMES2)\n",
    "random.shuffle(TRAIN_FILENAMES2)\n",
    "SPLIT = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = int(train_len_tot*SPLIT)\n",
    "val_len = int(train_len_tot*(1-SPLIT))\n",
    "TRAIN_FILENAME_TRAIN=TRAIN_FILENAMES2[:train_len]\n",
    "TRAIN_FILENAME_VAL=TRAIN_FILENAMES2[train_len:]\n",
    "TEST_PATH = '/Users/chiyuan/Documents/learning/kaggle/sea_lion/KaggleNOAASeaLions/Test/'\n",
    "TEST_FILENAME = [item for item in os.listdir(TEST_PATH) if not item.startswith('.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "yield  665.jpg\n",
      "1/5 [=====>........................] - ETA: 66s - loss: 0.0000e+00 - acc: 0.4788yield  316.jpg\n",
      "2/5 [===========>..................] - ETA: 44s - loss: 0.0000e+00 - acc: 0.4742yield  587.jpg\n",
      "3/5 [=================>............] - ETA: 29s - loss: 0.0000e+00 - acc: 0.4737yield  169.jpg\n",
      "4/5 [=======================>......] - ETA: 14s - loss: 0.0000e+00 - acc: 0.4643yield  833.jpg\n",
      "5/5 [==============================] - 71s - loss: 0.0000e+00 - acc: 0.4517     \n",
      "yield  666.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x125f26ed0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=2\n",
    "train_generator = generate_image_and_gt(TRAIN_FILENAME_TRAIN,TRAIN_PATH2,TRAIN_GT_PATH2,batch_size=batch_size)\n",
    "val_generator = generate_image_and_gt(TRAIN_FILENAME_VAL,TRAIN_PATH2,TRAIN_GT_PATH2,batch_size=batch_size)\n",
    "model.fit_generator(train_generator, \n",
    "                    steps_per_epoch=5, \n",
    "                    epochs=1,\n",
    "                    #validation_data=val_generator,\n",
    "                    #validation_steps=val_len//batch_size\n",
    "                   )\n",
    "#model.save_weights(\"sea_lion_count.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yield  195.jpg\n",
      "yield  616.jpg\n",
      "yield  651.jpg\n"
     ]
    }
   ],
   "source": [
    "predict_train = model.predict_generator(train_generator,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.35289609,  0.15443744,  0.26292479,  0.12204544,  0.10769621],\n",
       "        [ 0.34160167,  0.15535995,  0.25667459,  0.13065055,  0.11571325],\n",
       "        [ 0.43500885,  0.12122833,  0.28171253,  0.08394188,  0.07810835],\n",
       "        ..., \n",
       "        [ 0.24546218,  0.20358321,  0.24095453,  0.1469174 ,  0.1630827 ],\n",
       "        [ 0.23010258,  0.20218502,  0.22876491,  0.16017143,  0.17877604],\n",
       "        [ 0.23744   ,  0.20424716,  0.23830767,  0.1473209 ,  0.17268425]],\n",
       "\n",
       "       [[ 0.47647429,  0.09694506,  0.29702857,  0.05601815,  0.07353386],\n",
       "        [ 0.48623556,  0.09607685,  0.29657483,  0.05466431,  0.06644838],\n",
       "        [ 0.48644873,  0.09592693,  0.30080158,  0.05126247,  0.06556026],\n",
       "        ..., \n",
       "        [ 0.19783199,  0.22322848,  0.22431791,  0.15281299,  0.20180863],\n",
       "        [ 0.20012204,  0.22909155,  0.22708438,  0.15189308,  0.19180889],\n",
       "        [ 0.20865662,  0.2107048 ,  0.22902113,  0.14689575,  0.20472161]],\n",
       "\n",
       "       [[ 0.17393167,  0.16854611,  0.15285924,  0.29958197,  0.20508103],\n",
       "        [ 0.3683686 ,  0.09548899,  0.19724882,  0.20401943,  0.13487414],\n",
       "        [ 0.59775954,  0.05052827,  0.21454246,  0.0864671 ,  0.05070256],\n",
       "        ..., \n",
       "        [ 0.46469745,  0.10314055,  0.27064869,  0.08547386,  0.07603948],\n",
       "        [ 0.48166013,  0.09576466,  0.2687037 ,  0.0816493 ,  0.07222226],\n",
       "        [ 0.47847649,  0.09774753,  0.27240884,  0.07905444,  0.07231273]],\n",
       "\n",
       "       [[ 0.77734202,  0.01709796,  0.17726627,  0.01844009,  0.00985364],\n",
       "        [ 0.77734202,  0.01709796,  0.17726627,  0.01844009,  0.00985364],\n",
       "        [ 0.77734202,  0.01709796,  0.17726627,  0.01844009,  0.00985364],\n",
       "        ..., \n",
       "        [ 0.05595974,  0.30431503,  0.11284262,  0.21500653,  0.31187606],\n",
       "        [ 0.13257563,  0.28105506,  0.19305305,  0.16415191,  0.22916433],\n",
       "        [ 0.08592965,  0.29630786,  0.14833044,  0.19196299,  0.27746907]]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.jpg\n",
      "42.jpg\n",
      "1 yield\n",
      "(2, 512, 512, 3)\n",
      "(2, 262144, 5)\n",
      "43.jpg\n",
      "44.jpg\n",
      "1 yield\n",
      "(2, 512, 512, 3)\n",
      "(2, 262144, 5)\n",
      "45.jpg\n",
      "46.jpg\n",
      "1 yield\n",
      "(2, 512, 512, 3)\n",
      "(2, 262144, 5)\n",
      "47.jpg\n",
      "48.jpg\n",
      "1 yield\n",
      "(2, 512, 512, 3)\n",
      "(2, 262144, 5)\n",
      "49.jpg\n",
      "50.jpg\n",
      "1 yield\n",
      "(2, 512, 512, 3)\n",
      "(2, 262144, 5)\n"
     ]
    }
   ],
   "source": [
    "train_generator = generate_image_and_gt(TRAIN_FILENAMES,batch_size=2)\n",
    "for x,y in train_generator:\n",
    "    print x.shape\n",
    "    print y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/chiyuan/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\u001b[0m(719)\u001b[0;36m_input_request\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    717 \u001b[0;31m            \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    718 \u001b[0;31m                \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 719 \u001b[0;31m                \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    720 \u001b[0;31m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    721 \u001b[0;31m                \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u0001\u0002ipdb> \u0001\u0002q\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 512, 512, 3)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 512, 512, 5)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_gt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 262144, 5)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_gt_reshape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2621440, 1)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_categorical(imgs_gt[...,np.newaxis]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
